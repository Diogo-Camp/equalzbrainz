import os
import subprocess
import ollama
import json

# ğŸ§  MemÃ³ria da conversa (carrega de arquivo se existir)
hist_path = "memory/conversa.json"
if os.path.exists(hist_path):
    with open(hist_path, "r", encoding="utf-8") as f:
        conversa = json.load(f)
else:
    conversa = [
        {
            "role": "system",
            "content": (
                "VocÃª Ã© um assistente com acesso ao terminal Linux. "
                "Pode executar comandos reais usando 'cmd: <comando>' "
                "ou criar arquivos usando 'file: <caminho>' seguido por 'conteÃºdo:'. "
                "Lembre-se do que foi feito anteriormente e responda de forma clara."
            )
        }
    ]

# ğŸ“‚ ExecuÃ§Ã£o de comandos do terminal
def executar_comando_terminal(comando):
    try:
        resultado = subprocess.check_output(
            comando, shell=True, stderr=subprocess.STDOUT, text=True
        )
        return resultado
    except subprocess.CalledProcessError as e:
        return f"Erro ao executar: {e.output}"

# ğŸ“ CriaÃ§Ã£o de arquivos
def criar_arquivo(caminho, conteudo):
    try:
        os.makedirs(os.path.dirname(caminho), exist_ok=True)
        with open(caminho, 'w', encoding='utf-8') as f:
            f.write(conteudo)
        return f"âœ… Arquivo '{caminho}' criado com sucesso."
    except Exception as e:
        return f"âŒ Erro ao criar arquivo: {str(e)}"

# ğŸ”„ Loop principal
while True:
    user_input = input("\nğŸ§½ VocÃª: ")

    if user_input.strip().lower() in ["exit", "sair"]:
        break
    if user_input.strip().lower() == "clear":
        conversa = conversa[:1]  # MantÃ©m apenas o system prompt
        print("\nğŸ” MemÃ³ria apagada. ComeÃ§ando do zero.")
        continue

    conversa.append({"role": "user", "content": user_input})

    # â³ Streaming da resposta
    print("\nğŸ¤– Mistral: ", end="", flush=True)
    stream = ollama.chat(model='mistral:7b-instruct-q4_K_M', messages=conversa, stream=True)

    texto = ""
    for parte in stream:
        token = parte['message']['content']
        print(token, end="", flush=True)
        texto += token

    print()  # Nova linha
    conversa.append({"role": "assistant", "content": texto})

    # ğŸ“… CriaÃ§Ã£o de arquivo
    if texto.startswith("file:"):
        try:
            linhas = texto.splitlines()
            caminho = linhas[0].replace("file:", "").strip()
            idx_conteudo = next(i for i, l in enumerate(linhas) if l.startswith("conteÃºdo:"))
            conteudo = "\n".join(linhas[idx_conteudo + 1:])
            resultado = criar_arquivo(caminho, conteudo)
        except Exception as e:
            resultado = f"âŒ Erro ao interpretar criaÃ§Ã£o de arquivo: {str(e)}"

        print(f"\nğŸ“ Resultado da criaÃ§Ã£o:
{resultado}")
        conversa.append({"role": "user", "content": f"Resultado da criaÃ§Ã£o:
{resultado}"})

    # ğŸ’» ExecuÃ§Ã£o de comando
    elif texto.startswith("cmd:"):
        comando = texto.replace("cmd:", "").strip()
        resultado = executar_comando_terminal(comando)
        print(f"\nğŸ“Š Resultado do comando:
{resultado}")
        conversa.append({"role": "user", "content": f"Resultado do comando '{comando}':
{resultado}"})

    # ğŸ”¢ Salva memÃ³ria em disco
    os.makedirs("memory", exist_ok=True)
    with open(hist_path, "w", encoding="utf-8") as f:
        json.dump(conversa, f, ensure_ascii=False, indent=2)
